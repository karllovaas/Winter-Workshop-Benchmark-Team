{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0fe325",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Development Juptyer Notebooks for The Benchmark Calculation Overtime . \n",
    "''' \n",
    "\n",
    "from abc import abstractmethod, ABC \n",
    "import pandas as pd \n",
    "from typing import Iterable, List, Optional\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a36c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "pulling cleaned data into the notebook \n",
    "'''\n",
    "df = pd.read_csv(\"bloomberg_data_cleaned.csv\")\n",
    "\n",
    "#set date to datetime object \n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.set_index([\"date\",\"ticker\"],inplace= True)\n",
    "pd.set_option('display.float_format', '{:,.4f}'.format)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "==========================================================\n",
    "         Index Composition and Reconstitution Class\n",
    "==========================================================\n",
    "data. is our base dataframe \n",
    "\"\"\"\n",
    "from dataframehelper import DataframeHelper\n",
    "\n",
    "\n",
    "class IndexComposer:\n",
    "    '''     \n",
    "    Based on maria, filtering functions. Index Composer will work in conjuction with \n",
    "    the benchmark class. It's primary purpose is to take in a single day and\n",
    "    and stock data universe as inputs and spit out subset of tickers that will constitute \n",
    "    the midcap growth index.  \n",
    "    ''' \n",
    "    def __init__(self,data: pd.DataFrame, day: datetime ) -> None: \n",
    "        self.data: pd.DataFrame = data\n",
    "        self.df_helper = DataframeHelper(data) \n",
    "        self.day: datetime = day\n",
    "        self.day_slice: pd.DataFrame = self.df_helper.slice_by_day(day)\n",
    "        self._midcap_800: pd.DataFrame = self.get_midcap_800()\n",
    "        self.growth_subset: pd.Series = self.growth_subset_filter_v1() #type: ignore \n",
    "        self.growth_subset_weights = self.get_weights() \n",
    "        self.growth_subset_shares = self.get_share_count()  \n",
    "\n",
    "    def get_midcap_800(self) -> pd.DataFrame: \n",
    "        ''' This needs to be date based: we only want to drop NA values \n",
    "            for a given day\n",
    "        '''\n",
    "        # get all of the data for that day \n",
    "        df = self.day_slice \n",
    "        # filter only for stocks that are not NA. \n",
    "        df = df.dropna(subset = [\"market_cap\"]).copy()\n",
    "        #sort from largest to smallest \n",
    "        df.sort_values(by = \"market_cap\", ascending= False, inplace= True)\n",
    "        # filter out the largest 200 stocks \n",
    "        df = df.iloc[199:,]\n",
    "        return df\n",
    "\n",
    "\n",
    "    def compute_growth_probability(self, k=5.0) -> pd.Series:\n",
    "        '''\n",
    "        Computing Growth Probability\n",
    "\n",
    "        Since right now we only have P/B data, we can approximate growth\n",
    "        classification using inverse price-to-book (B/P) mapped into a \n",
    "        smooth probability via a logistic function.\n",
    "        '''\n",
    "        midcap = self._midcap_800\n",
    "        pb = midcap[\"price_to_book\"].astype(float)\n",
    "\n",
    "        #convert P/B to B/P since Russell uses B/P\n",
    "        bp = np.where((pb > 0 ) & np.isfinite(pb), 1.0 / pb, np.nan)\n",
    "        bp = pd.Series(bp, index=midcap.index)\n",
    "        bp = bp.fillna(bp.median()) # to fill empty values (for later computation)\n",
    "\n",
    "        z = (bp -bp.mean()) / (bp.std(ddof=0) + 1e-12) # z-score for standardization\n",
    "        z_growth = -z # low B/P -> growth, so now high z_growth -> more growthlike\n",
    "\n",
    "        #normalizing\n",
    "        #very neg z_growth -> 0 (value), very pos z_growth -> 1 (growth)\n",
    "        p = 1 / (1 + np.exp(-k * z_growth)) \n",
    "\n",
    "        return pd.Series(p, index=midcap.index, name=\"p_growth\")\n",
    "    \n",
    "    def growth_subset_filter_v1(self) -> pd.Series:\n",
    "        growth_subset_mask = self.compute_growth_probability() > .85\n",
    "        growth_subset = self._midcap_800.loc[growth_subset_mask]\n",
    "        return pd.Series(growth_subset.index.get_level_values(\"ticker\"))\n",
    "    \n",
    "    def get_weights(self) -> pd.Series: \n",
    "        df = self.day_slice\n",
    "        df = df.reset_index() \n",
    "        df = df.set_index(\"ticker\")\n",
    "        growth_subset = self.growth_subset\n",
    "        df = df.loc[growth_subset]\n",
    "        total_cap = df[\"market_cap\"].sum() \n",
    "        return df[\"market_cap\"] / total_cap\n",
    "    \n",
    "    def get_share_count(self) -> pd.Series: \n",
    "        df = self.day_slice\n",
    "        df = df.reset_index() \n",
    "        df = df.set_index(\"ticker\")\n",
    "        growth_subset = self.growth_subset\n",
    "        df = df.loc[growth_subset]\n",
    "        return df[\"market_cap\"] / df[\"close_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee2ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Benchmark:\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    def __init__(self, data: pd.DataFrame, benchmark_start_val: float): \n",
    "        self.data: pd.DataFrame = data\n",
    "        self.cur_constituents: pd.Series #this is all of current member of the index. \n",
    "        self.dates: pd.Series = pd.Series(self.data.index.get_level_values(\"date\").unique())\n",
    "        self.cur_date: datetime  = self.dates[0]\n",
    "        self._i: int = 0 \n",
    "        self.bechmark_timeseries = pd.Series(data = 0.0, index = self.dates)\n",
    "        self.benchmark_divisor: float = 1\n",
    "        self.quarterly_recon_dates: List[datetime] = []\n",
    "        self._get_quarterly_reconst_dates()\n",
    "        self.annual_recon_dates = self._get_annual_reconstitution_dates() \n",
    "        self.benchmark_makeup_dict: dict = {}\n",
    "        self.cur_divisor: float = 0.0\n",
    "        self.DataHelper = DataframeHelper(self.data)\n",
    "\n",
    "    #=========================================================\n",
    "    #          Benchmark Constitution Methods\n",
    "    #========================================================\n",
    "    def calculate_benchmark(self): \n",
    "        # set the benchmark constitution on the first day of the calculation\n",
    "        composer = IndexComposer(self.data, self.cur_date)\n",
    "        self.cur_constituents = composer.growth_subset\n",
    "        self.benchmark_makeup_dict[self.cur_date] = composer.growth_subset\n",
    "        \n",
    "        # calculate benchmark for the first day\n",
    "        print(f\"calculating benchmark for the first day {self.cur_date}\")\n",
    "        day_df = composer.day_slice\n",
    "        day_df = day_df.reset_index() \n",
    "        day_df.set_index(\"ticker\",inplace= True)\n",
    "        day_df = day_df.loc[composer.growth_subset]\n",
    "\n",
    "        # add columns to day df that we need for calculating the cap adjusted benchmark \n",
    "        day_df[\"weights\"] = composer.growth_subset_weights\n",
    "        day_df[\"shares\"] = composer.growth_subset_shares\n",
    "        day_df[\"weight_adjusted_cap\"] = day_df[\"weights\"] * day_df[\"shares\"] * day_df[\"close_price\"]\n",
    "        \n",
    "        cap_weighted_benchmark_numerator = day_df[\"weight_adjusted_cap\"].sum() \n",
    "        self.cur_divisor = cap_weighted_benchmark_numerator / 1839.00  # hardcoded for now #todo will updated soon \n",
    "        first_benchmark_price = cap_weighted_benchmark_numerator / self.cur_divisor\n",
    "        self.bechmark_timeseries.loc[self.cur_date] = first_benchmark_price #type: ignore\n",
    "\n",
    "        while self.next_date() is not None:\n",
    "            if self.cur_date in self.annual_recon_dates:\n",
    "                print(f\"{self.cur_date} is an reconsitution date\" )\n",
    "                composer = IndexComposer(self.data,self.cur_date)\n",
    "                self.benchmark_makeup_dict[self.cur_date] = composer.growth_subset\n",
    "                # when there is recomposition we'll need to rescale the divisor, we'll take the new bench mark\n",
    "                # constitution, weights and share counts and calculate what divisor makes its such that the \n",
    "                # new constitution equals the previous constitutions benchmark value\n",
    "                prev_date = self.dates[self._i - 2]\n",
    "\n",
    "                # add columns to day df that we need for calculating the cap adjusted benchmark \n",
    "                prev_day_df = self.DataHelper.slice_by_day(prev_date)\n",
    "                prev_day_df = prev_day_df.reset_index() \n",
    "                prev_day_df.set_index(\"ticker\",inplace= True)\n",
    "                prev_day_df = prev_day_df.loc[composer.growth_subset]\n",
    "                prev_day_df[\"weights\"] = composer.growth_subset_weights\n",
    "                prev_day_df[\"shares\"] = composer.growth_subset_shares\n",
    "                prev_day_df[\"weight_adjusted_cap\"] = prev_day_df[\"weights\"] * prev_day_df[\"shares\"] * prev_day_df[\"close_price\"]\n",
    "                cap_weighted_benchmark_numerator = prev_day_df[\"weight_adjusted_cap\"].sum()\n",
    "\n",
    "                self.cur_divisor =  cap_weighted_benchmark_numerator / self.bechmark_timeseries.loc[prev_date]\n",
    "                print(f\" cur_divisor is {self.cur_divisor},  self.bechmark_timeseries.loc[prev_date])\")\n",
    "            \n",
    "            # add columns to day df that we need for calculating the cap adjusted benchmark \n",
    "            day_df = self.DataHelper.slice_by_day(self.cur_date)\n",
    "            day_df.reset_index(inplace= True)\n",
    "            day_df.set_index(\"ticker\",inplace= True)\n",
    "            day_df = day_df.loc[composer.growth_subset]\n",
    "            day_df[\"weights\"] = composer.growth_subset_weights\n",
    "            day_df[\"shares\"] = composer.growth_subset_shares\n",
    "            day_df[\"weight_adjusted_cap\"] = day_df[\"weights\"] * day_df[\"shares\"] * day_df[\"close_price\"]\n",
    "            cap_weighted_benchmark_numerator = day_df[\"weight_adjusted_cap\"].sum() \n",
    "            benchmark_price = cap_weighted_benchmark_numerator / self.cur_divisor\n",
    "            self.bechmark_timeseries.loc[self.cur_date] = benchmark_price #type: ignore\n",
    "\n",
    "    #========================================================\n",
    "    #           Date Handling Methods: \n",
    "    #========================================================\n",
    "    \n",
    "    def _get_quarterly_reconst_dates(self) -> None: \n",
    "        \"\"\"\n",
    "        Last trading of the months January, April, July, October\n",
    "        \"\"\"\n",
    "        s_dates = self.dates\n",
    "        l_dates: list[datetime] = self.dates.to_list() \n",
    "        for year in range(l_dates[0].year, l_dates[-1].year + 1):\n",
    "            for month in [1,4,7,10]:\n",
    "                year_month_mask = (s_dates.dt.year == year) &  (s_dates.dt.month == month) #type: ignore \n",
    "                self.quarterly_recon_dates += [s_dates[year_month_mask].iloc[-1]]\n",
    "\n",
    "    def _get_annual_reconstitution_dates(self) -> List[datetime]:\n",
    "        \"\"\"Maria: method\"\"\"\n",
    "        dates = self.data.index.get_level_values(\"date\").unique()\n",
    "        recon = []\n",
    "        years = pd.DatetimeIndex(dates).year.unique()\n",
    "        for year in years:\n",
    "            june = [d for d in dates if d.year == year and d.month == 6]\n",
    "            if not june:\n",
    "                continue\n",
    "            fridays = [d for d in june if pd.Timestamp(d).weekday() == 4] # Monday=0 ... Friday=4\n",
    "            if not fridays:\n",
    "                continue\n",
    "\n",
    "            fridays = sorted(fridays)\n",
    "            if len(fridays) >= 4:\n",
    "                recon.append(fridays[3]) # 4th Friday (0-indexed)\n",
    "            else:\n",
    "                recon.append(fridays[-1]) # fallback: last Friday available\n",
    "        return recon\n",
    "\n",
    "\n",
    "    def is_reconstitution_date(self) -> bool:  \n",
    "        out = False\n",
    "        annual_recon_dates = self._get_annual_reconstitution_dates()\n",
    "        if self.cur_date in annual_recon_dates: \n",
    "            return True\n",
    "        if self.cur_date in self.quarterly_recon_dates: \n",
    "            return True \n",
    "        return False \n",
    "\n",
    "    def set_cur_date(self, day: datetime):\n",
    "        if day not in self.dates.to_list(): \n",
    "            raise ValueError(\"Invalid Day Selected\") \n",
    "        self.cur_date = day\n",
    "        self._i = self.dates.to_list().index(day)\n",
    "        \n",
    "\n",
    "    def next_date(self) -> Optional[datetime]:\n",
    "        if self._i < self.dates.__len__(): \n",
    "            self.cur_date = self.dates[self._i]\n",
    "            self._i += 1 \n",
    "            return self.cur_date\n",
    "        else:\n",
    "            return None \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cecf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeHelper:\n",
    "    DATAOG: pd.DataFrame\n",
    "    def __init__(self, data: pd.DataFrame) -> None:\n",
    "        DataframeHelper.DATAOG = data \n",
    "        self.data = data \n",
    "    \n",
    "    def slice_by_ticker(self,ticker: str) -> pd.DataFrame:\n",
    "        ticker_mask = self.data.index.get_level_values(\"ticker\") == ticker\n",
    "        return self.data.loc[ticker_mask]\n",
    "\n",
    "    def slice_by_day(self, day: datetime) -> pd.DataFrame: \n",
    "        day_mask = self.data.index.get_level_values(\"date\") == day\n",
    "        return self.data.loc[day_mask]\n",
    "    \n",
    "    def slice_any_row_with_na(self) -> pd.DataFrame:\n",
    "        NA_mask = self.data.isna() \n",
    "        return self.data[NA_mask.any(axis=1)]\n",
    "    \n",
    "    def slice_complete_na_rows(self) -> pd.DataFrame: \n",
    "        #todo: \n",
    "        return pd.DataFrame()\n",
    "    def slice_by_day_range(self, start_date: datetime, end_date: datetime) -> pd.DataFrame: \n",
    "        #todo \n",
    "        return pd.DataFrame() \n",
    "    \n",
    "    @staticmethod\n",
    "    def _rolling_growth_rate(price_to_sales_series : pd.Series) -> float:  \n",
    "        lookback_days = 252 #one trading year \n",
    "        #see if there are NA values, there are growth is NA \n",
    "        NA_mask = price_to_sales_series.isna()\n",
    "        if price_to_sales_series.loc[NA_mask].__len__() > 0:\n",
    "            return np.nan\n",
    "        # else slope of linear fit is growth rate\n",
    "        x_arbitrary = range(price_to_sales_series.__len__())\n",
    "        slope, intercept = np.polyfit(x_arbitrary, price_to_sales_series,1) \n",
    "        return slope*1000\n",
    "        \n",
    "    def add_roling_sales_growth_col(self):\n",
    "        # add rolling sales growth , not very performant \n",
    "        self.data[\"1year_PtoS_growth\"] = 0.0\n",
    "        for ticker in self.data.index.get_level_values(\"ticker\").unique():\n",
    "            df_slice = self.slice_by_ticker(ticker)\n",
    "            df_slice[\"rolling_growth\"] = df_slice[\"price_to_sales\"].rolling(252,min_periods= 252).apply(self._rolling_growth_rate)\n",
    "            ticker_mask = df.index.get_level_values(\"ticker\") == ticker\n",
    "            self.data.loc[ticker_mask,\"1year_PtoS_growth\"] = df_slice[\"rolling_growth\"]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
